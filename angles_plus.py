# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 (pymycobot)
[ê°œì„  ë²„ì „ v5.11.1 - YOLO + íšŒì „ê° ë³´ì • + Zì¶• ë†’ì´ ë³´ì •]
(í•¸ë“œì…°ì´í¬ ACK ì´ë²¤íŠ¸ ì¶”ê°€íŒ)
"""

import threading
import cv2
import time
import argparse
import numpy as np
from ultralytics import YOLO
import queue  # [!!! v5.9 ì¶”ê°€ !!!]

# ---------------------------------------------------------------------------
# 0. ë¡œë´‡ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------------------------------
try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass

# ---------------------------------------------------------------------------
# 1. ì „ì—­ ë³€ìˆ˜, Lock, Event [!!! v5.11 ìˆ˜ì • !!!]
# ---------------------------------------------------------------------------
g_target_object = None  # [v5.11] YOLOê°€ ê³„ì‚°í•œ ë¡œë´‡ ì¢Œí‘œ + í´ë˜ìŠ¤ ID + ê°ë„
g_coord_lock = threading.Lock()  # ìœ„ ì¢Œí‘œë¥¼ ì•ˆì „í•˜ê²Œ ì½ê³  ì“°ê¸° ìœ„í•œ Lock
args = None  # argparse ê²°ê³¼

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í†µì‹ ìš© Event
e_robot_task_ready = threading.Event()  # YOLO -> Robot "ë¬¼ê±´ ì°¾ì•˜ë‹¤, ì¶œë°œí•´"
e_robot_task_done = threading.Event()  # Robot -> YOLO "ì‘ì—… ëë‚¬ë‹¤, ë‹¤ì‹œ ì°¾ì•„ë„ ë¼"
e_robot_task_done.set()  # ì´ˆê¸° ìƒíƒœëŠ” "ì‘ì—… ì™„ë£Œ" (ì¦‰ì‹œ íƒì§€ ì‹œì‘ ê°€ëŠ¥)

# [v5.12 ì¶”ê°€] ë¡œë´‡ì´ YOLOì˜ ready ì‹ í˜¸ë¥¼ ìˆ˜ì‹ (ack)í–ˆìŒì„ ì•Œë¦¬ëŠ” Event
e_robot_ack_received = threading.Event()

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í”„ë ˆì„ ì „ë‹¬ìš© Queue
frame_queue = queue.Queue(maxsize=1)
# ë””ë²„ê·¸ ë° GUI í‘œì‹œìš© (YOLOê°€ ì²˜ë¦¬í•œ ìµœì¢… í”„ë ˆì„)
processed_frame_buffer = {"frame": None}

# ---------------------------------------------------------------------------
# 2. ë¡œë´‡ ê¸°ë³¸ ìì„¸/ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê°’ [!!! v5.11 ìˆ˜ì • !!!]
# ---------------------------------------------------------------------------
POSES = {
    "Home": [59.8, -215.9, 354.6, -175.33, 8.65, 86.68],  # ì‹œì‘/ëŒ€ê¸° ìœ„ì¹˜
    "Place": [105.8, -65.0, 483.4, -116.46, 4.87, -78.69],  # (ì‚¬ìš©ì ì •ì˜ - í˜„ì¬ ë¡œì§ì—ì„  ë¯¸ì‚¬ìš©)
    "Box1": [291.3, 210.0, 200, -172.57, -1.46, -87.15],  # 1. íŒŒë€ìƒ‰ ë†“ëŠ” ê³³
    "Box2": [333.4, 11.7, 200, -175.19, -0.08, -89.53],  # 2. ë¹¨ê°„ìƒ‰ ë†“ëŠ” ê³³
    "Box3": [319.9, -169.5, 200, -172.32, -2.86, -87.15],  # 3. ë…¸ë€ìƒ‰ ë†“ëŠ” ê³³
    "Box1_up": [229.8, 132.6, 386.4, -147.34, 9.15, -74.66],  # Box1 ì ‘ê·¼(ìœ„)
    "Box2_up": [264.0, -1.3, 379.0, -153.71, 11.7, -106.33],  # Box2 ì ‘ê·¼(ìœ„)
    "Box3_up": [228.0, -203.0, 362.8, -146.13, 15.2, -149.53],  # Box3 ì ‘ê·¼(ìœ„)
}

DEFAULT_SPEED = 20
CAMERA_MATRIX = np.array([
    [539.13729067, 0.0, 329.02126026],
    [0.0, 542.34217387, 242.10995541],
    [0.0, 0.0, 1.0]
])
DIST_COEFFS = np.array([[0.20528603, -0.76664068, -0.00096614, 0.00111892, 0.97630004]])

# [!!! v5.11 ì¶”ê°€ !!!] ê°ë„ ê³„ì‚°ì„ ìœ„í•œ HSV ìƒ‰ìƒ ë²”ìœ„
# (class_id 0=blue, 1=red, 2=yellow ë§¤í•‘)
COLOR_RANGES = {
    "red": ([0, 120, 70], [10, 255, 255]),
    "green": ([35, 80, 40], [85, 255, 255]),
    "blue": ([90, 80, 70], [130, 255, 255]),
    "yellow": ([20, 100, 100], [35, 255, 255]),
    "red2": ([170, 120, 70], [180, 255, 255])
}

# ---------------------------------------------------------------------------
# 3. í”½ì…€ ì¢Œí‘œ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜ (v5.9 ì›ë³¸)
# ---------------------------------------------------------------------------
def pixel_to_robot(cx, cy, distance_cm, frame_w, frame_h):
    # (v5.9ì™€ ë™ì¼)
    pts = np.array([[[cx, cy]]], dtype=np.float32)
    undistorted_pts = cv2.undistortPoints(pts, CAMERA_MATRIX, DIST_COEFFS, P=None)
    norm_x, norm_y = undistorted_pts[0, 0]
    scale_z = distance_cm * 10.0
    x_cam = norm_x * scale_z
    y_cam = norm_y * scale_z
    
    TCP_BASE_OFFSET_X = 59.8
    TCP_BASE_OFFSET_Y = -215.9
    CAMERA_TO_TCP_OFFSET_X = 75.0
    CAMERA_TO_TCP_OFFSET_Y = 0.0
    
    robot_x = TCP_BASE_OFFSET_X + CAMERA_TO_TCP_OFFSET_X + y_cam
    robot_y = TCP_BASE_OFFSET_Y + CAMERA_TO_TCP_OFFSET_Y + x_cam
    
    TCP_BASE_OFFSET_Z = 354.6
    robot_z_ignored = TCP_BASE_OFFSET_Z - scale_z
    
    return {"x": round(robot_x, 2), "y": round(robot_y, 2), "z_debug": round(robot_z_ignored, 2)}

# ---------------------------------------------------------------------------
# 4. [ì‹ ê·œ v5.9] ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ (ì´ˆê³ ì† ì˜ìƒ ìˆ˜ê¸‰)
# ---------------------------------------------------------------------------
def camera_read_thread(stop_event, cap, frame_queue):
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì‹œì‘")
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue
        
        try:
            frame_queue.put_nowait(frame)
        except queue.Full:
            pass
        
        time.sleep(0.01)
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 5. [!!! v5.11 ìˆ˜ì • !!!] 'YOLO + ê°ë„ ê³„ì‚°' ì²˜ë¦¬ ìŠ¤ë ˆë“œ (ëŠë¦° ë‘ë‡Œ)
# ---------------------------------------------------------------------------
def yolo_process_thread(stop_event, frame_queue, model):
    """Queueì—ì„œ í”„ë ˆì„ì„ êº¼ë‚´ì„œ YOLO ì˜ˆì¸¡ ë° ê°ë„ ê³„ì‚° ìˆ˜í–‰"""
    global g_target_object, g_coord_lock, processed_frame_buffer
    
    print("ğŸ§  YOLO 'ì²˜ë¦¬+ê°ë„ê³„ì‚°' ìŠ¤ë ˆë“œ ì‹œì‘")
    stable_frames = 0
    
    while not stop_event.is_set():
        # 1. ë¡œë´‡ì´ ì‘ì—… ì¤‘ì´ë©´ íƒì§€ ì•ˆ í•¨
        if not e_robot_task_done.is_set():
            stable_frames = 0
            time.sleep(0.1)
            continue
            
        # 2. ë¡œë´‡ì´ ì‰¬ê³  ìˆìœ¼ë©´, Queueì—ì„œ ìµœì‹  í”„ë ˆì„ êº¼ë‚´ê¸°
        try:
            frame = frame_queue.get(timeout=0.1)
        except queue.Empty:
            continue

        # 3. YOLO ì˜ˆì¸¡ (ê°€ì¥ ëŠë¦° ë¶€ë¶„)
        results = model.predict(frame, imgsz=640, conf=0.6, verbose=False)
        
        # YOLO ê²°ê³¼ í”„ë ˆì„ (ì‹œê°í™”)
        frame_vis = results[0].plot()

        boxes = results[0].boxes.xyxy.cpu().numpy()
        classes = results[0].boxes.cls.cpu().numpy()

        # 5. ë¬¼ì²´ ê°ì§€ ë° ì¢Œí‘œ/ê°ë„ ê³„ì‚°
        if len(boxes) > 0:
            stable_frames += 1
            if stable_frames >= 3:  # 3í”„ë ˆì„ ì—°ì† ê°ì§€ ì‹œ "í™•ì •"
                x1, y1, x2, y2 = map(int, boxes[0])
                class_id = int(classes[0])
                
                cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
                distance_cm = 19.0  # ì„ì‹œ ê³ ì •ê±°ë¦¬
                
                # --- [!!! v5.11 ì¶”ê°€: ê°ë„ ê³„ì‚° ë¡œì§ !!!] ---
                angle = 0.0  # ê¸°ë³¸ê°’

                # 1. class_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒ‰ìƒ ì´ë¦„ ë§¤í•‘
                if class_id == 0: target_color_name = "blue"
                elif class_id == 1: target_color_name = "red"
                elif class_id == 2: target_color_name = "yellow"
                else: target_color_name = "blue" # ê°ì§€ ì•ˆë˜ë©´ íŒŒë€ìƒ‰ìœ¼ë¡œ ê°„ì£¼

                # 2. YOLOê°€ ê°ì§€í•œ ì˜ì—­(ROI)ë§Œ ì˜ë¼ëƒ„
                roi = frame[y1:y2, x1:x2]
                
                if roi.size > 0: # ROIê°€ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ
                    # 3. ìƒ‰ìƒ ê¸°ë°˜ ë§ˆìŠ¤í¬ ìƒì„±
                    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
                    
                    lower, upper = COLOR_RANGES[target_color_name]
                    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
                    
                    # 'red'ì˜ ê²½ìš° ë²”ìœ„ê°€ 2ê°œì¼ ìˆ˜ ìˆìŒ
                    if target_color_name == "red":
                         lower2, upper2 = COLOR_RANGES["red2"]
                         mask2 = cv2.inRange(hsv, np.array(lower2), np.array(upper2))
                         mask = cv2.bitwise_or(mask, mask2)

                    mask = cv2.erode(mask, None, iterations=2)
                    mask = cv2.dilate(mask, None, iterations=2)
                    
                    # 4. ì»¨íˆ¬ì–´ë¥¼ ì°¾ì•„ ìµœì†Œ ì‚¬ê°í˜•ìœ¼ë¡œ ê°ë„ ê³„ì‚°
                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    if contours:
                        c = max(contours, key=cv2.contourArea)
                        if cv2.contourArea(c) > 100: # ROI ë‚´ì—ì„œ ìµœì†Œ 100í”½ì…€ ì´ìƒ
                            rect = cv2.minAreaRect(c)
                            (w_box, h_box) = rect[1]
                            raw_angle = rect[2]

                            # OpenCV ê°ë„ ì •ê·œí™” (0~-90ë„ ë²”ìœ„)
                            if w_box < h_box:
                                angle = raw_angle + 90
                            else:
                                angle = raw_angle
                            
                            print(f"ğŸ“ ê°ë„ ê³„ì‚° ì„±ê³µ: {angle:.2f} (Raw: {raw_angle:.2f})")
                            
                            # (ë””ë²„ê·¸) ê³„ì‚°ëœ ì‚¬ê°í˜•ì„ ì›ë³¸ í”„ë ˆì„ì— ë‹¤ì‹œ ê·¸ë¦¬ê¸°
                            box = cv2.boxPoints(rect)
                            box = np.intp(box)
                            # boxì¢Œí‘œëŠ” ROI(x1, y1) ê¸°ì¤€ì´ë¯€ë¡œ ì›ë³¸ í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤í”„ì…‹
                            cv2.drawContours(frame_vis, [box + np.array([x1, y1])], 0, (0, 255, 255), 2)
                # --- [ê°ë„ ê³„ì‚° ë¡œì§ ì¢…ë£Œ] ---

                print(f"ğŸ¯ YOLO ê°ì²´ ì¤‘ì‹¬: ({cx}, {cy}), í´ë˜ìŠ¤ ID: {class_id}, ê°ë„: {angle:.2f}")
                h, w, _ = frame.shape
                coord = pixel_to_robot(cx, cy, distance_cm, w, h)

                with g_coord_lock:
                    # [v5.11] ì¢Œí‘œ, í´ë˜ìŠ¤ ID, ê°ë„ë¥¼ í•¨ê»˜ ì €ì¥
                    g_target_object = {"coord": coord, "class_id": class_id, "angle": angle}
                
                # --- [v5.12 ë³€ê²½: ACK í•¸ë“œì…°ì´í¬ ì¶”ê°€] ---
                e_robot_task_ready.set()   # ë¡œë´‡ ìŠ¤ë ˆë“œì—ê²Œ "ì¶œë°œ ì‹ í˜¸"
                e_robot_task_done.clear()  # "íƒì§€ ì„ë¬´ ì™„ë£Œ, ë¡œë´‡ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°"

                # ë¡œë´‡ì´ ì‹ í˜¸ë¥¼ ìˆ˜ì‹ (ACK)í•  ë•Œê¹Œì§€ ì ê¹ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
                if not e_robot_ack_received.wait(timeout=1.0):
                    print("âš ï¸ ë¡œë´‡ ì‘ë‹µ ì§€ì—° - YOLO: ACK íƒ€ì„ì•„ì›ƒ (1.0s)")
                else:
                    print("ğŸ¤ ë¡œë´‡ì´ YOLO ì‹ í˜¸ ìˆ˜ì‹ (ACK) í™•ì¸")
                e_robot_ack_received.clear()  # ë‹¤ìŒ ë¼ìš´ë“œë¥¼ ìœ„í•´ ì´ˆê¸°í™”
                # --- [ACK í•¸ë“œì…°ì´í¬ ì¢…ë£Œ] ---

                stable_frames = 0
        else:
            stable_frames = 0
        
        # 4. GUI í‘œì‹œìš© í”„ë ˆì„ (ì‹œê°í™” ìµœì¢…ë³¸)
        processed_frame_buffer["frame"] = frame_vis
            
    print("ğŸ§  YOLO 'ì²˜ë¦¬+ê°ë„ê³„ì‚°' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 6. [!!! v5.11 (Zì¶• ìˆ˜ì •) !!!] 'ë¡œë´‡ ì œì–´' ìŠ¤ë ˆë“œ (ëŠë¦° íŒ”ë‹¤ë¦¬)
# ---------------------------------------------------------------------------
def robot_control_thread(stop_event, mc, dry_run):
    """ë¡œë´‡ì˜ ëª¨ë“  ì›€ì§ì„(sleep í¬í•¨)ì„ ì „ë‹´"""
    global g_target_object, g_coord_lock
    
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì‹œì‘")
    
    # 1. (ë”± í•œ ë²ˆ) í™ˆ ìœ„ì¹˜ë¡œ ì´ë™
    if not dry_run and mc is not None:
        print("ğŸ¤– ë¡œë´‡ì„ í™ˆ ìœ„ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
        mc.send_coords(POSES["Home"], DEFAULT_SPEED)
        time.sleep(3)
        print("ğŸ  í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ  [dry-run] í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
    e_robot_task_done.set() # YOLOê°€ íƒì§€ë¥¼ ì‹œì‘í•˜ë„ë¡ í—ˆìš©

    # 2. ë©”ì¸ ë£¨í”„ (ì‹ í˜¸ ëŒ€ê¸°)
    while not stop_event.is_set():
        # e_robot_task_ready ì‹ í˜¸ê°€ ì˜¬ ë•Œê¹Œì§€ ë¬´í•œì • ëŒ€ê¸° (Blocking)
        if not e_robot_task_ready.wait(timeout=0.5):
            continue # 0.5ì´ˆë§ˆë‹¤ stop_event ì²´í¬

        # --- [v5.12 ë³€ê²½: YOLOì—ê²Œ ACK ì „ì†¡] ---
        # YOLOê°€ ë³´ë‚¸ ready ì‹ í˜¸ë¥¼ ìˆ˜ì‹ í–ˆìŒì„ ì•Œë ¤ì¤Œ (ì¦‰ì‹œ ACK)
        e_robot_ack_received.set()
        # --- [ACK ì „ì†¡ ì™„ë£Œ] ---

        # ì‹ í˜¸ê°€ ì˜¤ë©´, ì¢Œí‘œì™€ í´ë˜ìŠ¤ ID, ê°ë„ë¥¼ ê°€ì ¸ì™€ì„œ ì „ì²´ ì‹œí€€ìŠ¤ ì‹¤í–‰
        current_task = None
        with g_coord_lock:
            if g_target_object is not None:
                current_task = g_target_object.copy()
                g_target_object = None
        
        if current_task:
            current_coord = current_task["coord"]
            class_id = current_task["class_id"]
            angle = current_task.get("angle", 0.0)  # [!!! v5.11 ì¶”ê°€ !!!]
            
            print(f"ğŸ¤– ì¸ì‹ ì„±ê³µ â†’ ë¡œë´‡ ì´ë™ ì‹œì‘: {current_coord}, í´ë˜ìŠ¤ ID: {class_id}, ê°ë„: {angle:.2f}")
            pick_x = current_coord["x"]
            pick_y = current_coord["y"]

            # [v5.10] í´ë˜ìŠ¤ IDì— ë”°ë¼ ëª©í‘œ ìœ„ì¹˜ ê²°ì •
            if class_id == 0: # 1. Blue
                place_pose_name = "Box1"
                approach_pose_name = "Box1_up"
            elif class_id == 1: # 2. Red
                place_pose_name = "Box2"
                approach_pose_name = "Box2_up"
            elif class_id == 2: # 3. Yellow
                place_pose_name = "Box3"
                approach_pose_name = "Box3_up"
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤ ID: {class_id}. ê¸°ë³¸ê°’ 'Box2'ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                place_pose_name = "Box2"
                approach_pose_name = "Box2_up"
            
            # POSES ë”•ì…”ë„ˆë¦¬ì—ì„œ ì‹¤ì œ ì¢Œí‘œ ë°°ì—´ ê°€ì ¸ì˜¤ê¸°
            place_pose = POSES[place_pose_name]
            approach_pose = POSES[approach_pose_name]
            print(f"  â†³ ëª©í‘œ ì§€ì : {place_pose_name}")

            # [!!! v5.11 (Zì¶• ìˆ˜ì •) !!!] v8.0 ì½”ë“œì˜ ê³ ì • Z ê°’ ì‚¬ìš©
            Z_APPROACH = 300.0  # 1. ì ‘ê·¼ ë†’ì´ (v8.0 ê°’)
            Z_GRASP = 300.0     # 2. ì¡ê¸° ë†’ì´ (v8.0ì—ì„œ 260.0+40 = 300.0 ì´ì—ˆìŒ)
            Z_LIFT = 360.0      # 3. ë“¤ì–´ì˜¬ë¦° ë†’ì´ (v8.0ì—ì„œ 260.0+100 = 360.0 ì´ì—ˆìŒ)
            
            PICK_RX, PICK_RY, PICK_RZ = -175.33, 8.65, 86.68 # ê¸°ë³¸ RZ(Yaw) ìì„¸
            
            # [!!! v5.11 ìˆ˜ì • !!!] RZ(Yaw) ê°’ì— ê³„ì‚°ëœ ê°ë„ ë³´ì •
            yaw_offset = angle * 0.35 
            corrected_rz = PICK_RZ + yaw_offset
            print(f"  â†³ RZ ë³´ì •: {corrected_rz:.2f} (ê¸°ë³¸: {PICK_RZ} + ì˜¤í”„ì…‹: {yaw_offset:.2f} (ê°ë„: {angle:.2f}))")

            print(f"  â†³ ì ‘ê·¼Z={Z_APPROACH:.1f}, ì¡ê¸°Z={Z_GRASP:.1f}, ë“¤ì–´ì˜¬ë¦¬ê¸°Z={Z_LIFT:.1f}")

            if not dry_run and mc is not None:
                # --- v5.8 í”½ì—… ì‹œí€€ìŠ¤ (v5.10ì´ ë¡œì§ ì‚¬ìš©) ---
                mc.set_gripper_value(50, 80, 1) # ê·¸ë¦¬í¼ ì—´ê¸°
                time.sleep(1)
                
                mc.send_coords([pick_x, pick_y, Z_APPROACH, PICK_RX, PICK_RY, corrected_rz], 25, 0) # mode=0 (ê°ë„)
                time.sleep(3) # v8.0 ê¸°ì¤€ 3ì´ˆ
                
                mc.send_coords([pick_x, pick_y, Z_GRASP, PICK_RX, PICK_RY, corrected_rz], 15, 0) # mode=0 (ê°ë„)
                time.sleep(2) # v8.0 ê¸°ì¤€ 2ì´ˆ
                
                mc.set_gripper_value(8, 20, 1) # ê·¸ë¦¬í¼ ë‹«ê¸° (v8.0 ê¸°ì¤€)
                time.sleep(1.5)
                
                mc.send_coords([pick_x, pick_y, Z_LIFT, PICK_RX, PICK_RY, corrected_rz], 15, 0) # mode=0 (ê°ë„)
                time.sleep(1.5) # v8.0 ê¸°ì¤€ 1.5ì´ˆ
                
                mc.send_coords(approach_pose, DEFAULT_SPEED, 1) # ì˜ˆ: Box1_up (ì„ í˜•)
                time.sleep(3)
                mc.send_coords(place_pose, DEFAULT_SPEED, 1) # ì˜ˆ: Box1 (ì„ í˜•)
                time.sleep(3)
                
                mc.set_gripper_state(0, 80) # ê·¸ë¦¬í¼ ì—´ê¸°
                time.sleep(1.5)
                mc.send_coords(POSES["Home"], DEFAULT_SPEED) # mode=0 (ê¸°ë³¸ê°’)
                time.sleep(3)
                print("âœ… 1íšŒ í”¼í‚¹ ì™„ë£Œ")
            else:
                print("  [dry-run] ë¡œë´‡ ì—†ì´ ë™ì‘ íë¦„ë§Œ ì‹¤í–‰")
                time.sleep(5) # ì‹œë®¬ë ˆì´ì…˜ ëŒ€ê¸°

            # ì‘ì—…ì´ ëë‚¬ìŒì„ ì•Œë¦¼
            e_robot_task_ready.clear() # "ì¶œë°œ ì‹ í˜¸" ë„ê¸°
            e_robot_task_done.set()  # YOLOì—ê²Œ "ë‹¤ì‹œ íƒì§€ ì‹œì‘" ì‹ í˜¸
            
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 7. ë©”ì¸ ë£¨í”„ (GUI ë‹´ë‹¹)
# ---------------------------------------------------------------------------
def main():
    global args
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM0")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--speed", type=int, default=20)
    parser.add_argument("--camera", type=int, default=1)
    parser.add_argument("--dry-run", action="store_true")
    parser.add_argument("--model", type=str, default="best.pt")
    args = parser.parse_args()

    print(f"ğŸ§  YOLOv8 ëª¨ë¸('{args.model}') ë¡œë“œ ì¤‘...")
    try:
        model = YOLO(args.model, task="detect")
        print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
        
    stop_event = threading.Event()
    mc = None
    cap = None
    
    threads = []

    try:
        # 1) ë¡œë´‡ ì´ˆê¸°í™” (v5.9 ì›ë³¸)
        if not args.dry_run:
            try:
                mc = CobotClass(args.port, args.baud)
                time.sleep(0.5)
                mc.power_on()
                print("ğŸ”Œ ë¡œë´‡ Power ON ì™„ë£Œ")
                mc.set_gripper_value(50, 20, 1) # [!!! v5.11 (Zì¶• ìˆ˜ì •) !!!] v8.0 ê¸°ì¤€ìœ¼ë¡œ ì—´ê¸°
                time.sleep(1)
            except Exception as e:
                print(f"âŒ ë¡œë´‡ ì—°ê²° ì‹¤íŒ¨: {e}")
                mc = None
                args.dry_run = True
        else:
            print("ğŸŸ¡ dry-run ëª¨ë“œë¡œ ì‹œì‘")

        # 2) ì¹´ë©”ë¼ ì´ˆê¸°í™” (v5.9 ì›ë³¸)
        print(f"ğŸ“· ë©”ì¸: ì¹´ë©”ë¼ {args.camera}ë²ˆ ì—´ê¸° ì‹œë„...")
        cap = cv2.VideoCapture(args.camera)
        if not cap.isOpened():
            print(f"âš ï¸ {args.camera}ë²ˆ ì¹´ë©”ë¼ ì‹¤íŒ¨ â†’ 0ë²ˆìœ¼ë¡œ ì¬ì‹œë„")
            cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise Exception("camera open failed")
        print("âœ… ë©”ì¸: ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ")

        # 3) [v5.9] 3ê°œì˜ ìŠ¤ë ˆë“œ ì‹œì‘
        
        # Thread 1: ì¹´ë©”ë¼ ì½ê¸°
        t_cam = threading.Thread(
            target=camera_read_thread,
            args=(stop_event, cap, frame_queue),
            daemon=True
        )
        t_cam.start()
        threads.append(t_cam)

        # Thread 2: YOLO ì²˜ë¦¬ (v5.11 ìˆ˜ì •ë¨)
        t_yolo = threading.Thread(
            target=yolo_process_thread,
            args=(stop_event, frame_queue, model),
            daemon=True
        )
        t_yolo.start()
        threads.append(t_yolo)

        # Thread 3: ë¡œë´‡ ì œì–´ (v5.11 ìˆ˜ì •ë¨)
        t_robot = threading.Thread(
            target=robot_control_thread,
            args=(stop_event, mc, args.dry_run),
            daemon=True
        )
        t_robot.start()
        threads.append(t_robot)

        print("âœ… ë©”ì¸ ë£¨í”„ ì‹œì‘ (GUI í‘œì‹œ ë‹´ë‹¹, që¡œ ì¢…ë£Œ)")
        
        # 4) ë©”ì¸ ë£¨í”„ (GUIë§Œ ë‹´ë‹¹)
        while not stop_event.is_set():
            frame = processed_frame_buffer.get("frame")
            
            if frame is None:
                try:
                    frame = frame_queue.get_nowait()
                except queue.Empty:
                    time.sleep(0.01)
                    continue

            cv2.imshow("Camera View", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()
                break
                
            time.sleep(0.01)

    except Exception as e:
        print(f"ğŸš¨ ë©”ì¸ ë£¨í”„ì—ì„œ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        # 7) ì¢…ë£Œ ì²˜ë¦¬
        print("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€... ëª¨ë“  ìŠ¤ë ˆë“œ ì •ë¦¬ ì¤‘...")
        stop_event.set()
        
        for t in threads:
            t.join(timeout=1.0)
            
        if cap:
            cap.release()
        cv2.destroyAllWindows()
        if mc:
            mc.power_off()
        print("ğŸ”’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")


if __name__ == "__main__":
    main()
