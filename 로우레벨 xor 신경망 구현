<numpy>
로우레벨 XOR 신경망 구현 (1은닉층, 1출력층, 시그모이드)
python
복사
편집
import numpy as np

# 시그모이드 함수 & 그 도함수
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_deriv(x):
    return sigmoid(x) * (1 - sigmoid(x))

# 데이터 (XOR)
x_data = np.array([[0, 0],
                   [0, 1],
                   [1, 0],
                   [1, 1]])  # shape: (4, 2)
y_data = np.array([[0], [1], [1], [0]])     # shape: (4, 1)

# 랜덤 시드 고정
np.random.seed(42)

# 가중치 초기화
W1 = np.random.randn(2, 2)   # (입력2 → 은닉2)
b1 = np.zeros((1, 2))        # 은닉층 바이어스

W2 = np.random.randn(2, 1)   # (은닉2 → 출력1)
b2 = np.zeros((1, 1))        # 출력층 바이어스

# 하이퍼파라미터
learning_rate = 0.1
epochs = 10000

# 학습 반복
for epoch in range(epochs):
    # --- Forward ---
    z1 = np.dot(x_data, W1) + b1     # (4,2)
    a1 = sigmoid(z1)                 # 은닉층 활성화값

    z2 = np.dot(a1, W2) + b2         # (4,1)
    a2 = sigmoid(z2)                 # 출력값

    # --- Loss (Binary Cross Entropy) ---
    loss = -np.mean(y_data * np.log(a2 + 1e-8) + (1 - y_data) * np.log(1 - a2 + 1e-8))

    # --- Backpropagation ---
    dz2 = a2 - y_data                    # (4,1)
    dW2 = np.dot(a1.T, dz2) / 4         # (2,1)
    db2 = np.sum(dz2, axis=0, keepdims=True) / 4

    dz1 = np.dot(dz2, W2.T) * sigmoid_deriv(z1)  # (4,2)
    dW1 = np.dot(x_data.T, dz1) / 4              # (2,2)
    db1 = np.sum(dz1, axis=0, keepdims=True) / 4

    # --- Gradient Descent ---
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1

    # --- 출력 ---
    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")

<tensorflow and numpy>_______________________________________________________________________________________________________________________

import tensorflow as tf
import numpy as np

# 데이터 (XOR 문제)
x_data = np.array([[0, 0],
                   [0, 1],
                   [1, 0],
                   [1, 1]], dtype=np.float32)  # (4, 2)
y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)  # (4, 1)

# 변수 (가중치 & 바이어스) 정의
W1 = tf.Variable(tf.random.normal([2, 2]))
b1 = tf.Variable(tf.zeros([2]))

W2 = tf.Variable(tf.random.normal([2, 1]))
b2 = tf.Variable(tf.zeros([1]))

# 시그모이드 함수
def sigmoid(x):
    return 1 / (1 + tf.exp(-x))

# 손실 함수 (Binary Cross-Entropy)
def loss_fn(y_pred, y_true):
    return tf.reduce_mean(-y_true * tf.math.log(y_pred + 1e-7) - (1 - y_true) * tf.math.log(1 - y_pred + 1e-7))

# 학습률 및 옵티마이저
learning_rate = 0.1
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)

# 학습
for epoch in range(10001):
    with tf.GradientTape() as tape:
        # Forward pass
        z1 = tf.matmul(x_data, W1) + b1      # 은닉층 선형 연산
        a1 = sigmoid(z1)                     # 은닉층 출력

        z2 = tf.matmul(a1, W2) + b2          # 출력층 선형 연산
        y_pred = sigmoid(z2)                 # 최종 출력

        loss = loss_fn(y_pred, y_data)

    # Gradient 계산 및 적용
    gradients = tape.gradient(loss, [W1, b1, W2, b2])
    optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))

    # 출력 (1000마다)
    if epoch % 1000 == 0:
        print(f"Epoch {epoch:5d}: Loss = {loss.numpy():.5f}")

# 예측 출력
z1 = tf.matmul(x_data, W1) + b1
a1 = sigmoid(z1)
z2 = tf.matmul(a1, W2) + b2
y_pred = sigmoid(z2)

print("\n🔍 예측 결과:")
print(tf.round(y_pred).numpy())

# --- 학습 후 결과 ---
print("\n🔍 최종 예측 결과:")
a2_final = sigmoid(np.dot(sigmoid(np.dot(x_data, W1) + b1), W2) + b2)
print(np.round(a2_final, 4))
