# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 (pymycobot)
[ê°œì„  ë²„ì „ v5.9 - ì‹¤ì‹œê°„ì„± í™•ë³´]

ğŸ“Œ v5.8 ëŒ€ë¹„ í•µì‹¬ ë³€ê²½ì 
----------------------------------------------------
1. (ì§€ì—°/Lag í•´ê²°) 'ì¹´ë©”ë¼ ì½ê¸°'ì™€ 'YOLO ì˜ˆì¸¡' ìŠ¤ë ˆë“œ ë¶„ë¦¬
   - [ì‹ ê·œ] camera_read_thread: 1ì´ˆì— 30ë²ˆì”© í”„ë ˆì„ë§Œ ì½ì–´ì„œ Queueì— ë„£ìŒ (ë¹ ë¦„)
   - [ìˆ˜ì •] yolo_process_thread: Queueì—ì„œ í”„ë ˆì„ì„ êº¼ë‚´ì„œ predict (ëŠë¦¼)
   - (ê²°ê³¼) YOLOê°€ ì•„ë¬´ë¦¬ ëŠë ¤ë„, ì¹´ë©”ë¼ëŠ” 30fpsë¡œ ë¶€ë“œëŸ½ê²Œ ë³´ì„

2. (ë©ˆì¶¤/Freeze í•´ê²°) 'ë¡œë´‡ ì œì–´' ë¡œì§ì„ ë³„ë„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬
   - [ì‹ ê·œ] robot_control_thread: main()ì— ìˆë˜ ëª¨ë“  time.sleep()ê³¼
     mc.send_coords()ë¥¼ ì „ë‹´í•˜ëŠ” ìŠ¤ë ˆë“œ.
   - (ê²°ê³¼) ë¡œë´‡ì´ 20ì´ˆê°„ ì›€ì§ì—¬ë„, main()ì˜ cv2.imshow()ëŠ” ë©ˆì¶”ì§€ ì•ŠìŒ.

3. (ìì› ê´€ë¦¬) Queueì™€ Event ê°ì²´ ë„ì…
   - frame_queue: ì¹´ë©”ë¼->YOLO ì‹¤ì‹œê°„ í”„ë ˆì„ ì „ë‹¬ìš©
   - e_robot_task_ready: YOLO->ë¡œë´‡ "ë¬¼ê±´ ì°¾ì•˜ìœ¼ë‹ˆ ì›€ì§ì—¬" ì‹ í˜¸ìš©
   - e_robot_task_done: ë¡œë´‡->YOLO "ë™ì‘ ëë‚¬ìœ¼ë‹ˆ ë‹¤ì‹œ ì°¾ì•„" ì‹ í˜¸ìš©
"""

import threading
import cv2
import time
import argparse
import numpy as np
from ultralytics import YOLO
import queue  # [!!! v5.9 ì¶”ê°€ !!!]

# ---------------------------------------------------------------------------
# 0. ë¡œë´‡ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------------------------------
try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass

# ---------------------------------------------------------------------------
# 1. ì „ì—­ ë³€ìˆ˜, Lock, Event [!!! v5.9 ìˆ˜ì • !!!]
# ---------------------------------------------------------------------------
g_target_coordinate = None      # YOLOê°€ ê³„ì‚°í•œ ë¡œë´‡ ì¢Œí‘œ
g_coord_lock = threading.Lock() # ìœ„ ì¢Œí‘œë¥¼ ì•ˆì „í•˜ê²Œ ì½ê³  ì“°ê¸° ìœ„í•œ Lock
args = None                     # argparse ê²°ê³¼

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í†µì‹ ìš© Event
e_robot_task_ready = threading.Event()  # YOLO -> Robot "ë¬¼ê±´ ì°¾ì•˜ë‹¤, ì¶œë°œí•´"
e_robot_task_done = threading.Event()   # Robot -> YOLO "ì‘ì—… ëë‚¬ë‹¤, ë‹¤ì‹œ ì°¾ì•„ë„ ë¼"
e_robot_task_done.set() # ì´ˆê¸° ìƒíƒœëŠ” "ì‘ì—… ì™„ë£Œ" (ì¦‰ì‹œ íƒì§€ ì‹œì‘ ê°€ëŠ¥)

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í”„ë ˆì„ ì „ë‹¬ìš© Queue
# Queue(maxsize=1): íì— 1ê°œë§Œ ì €ì¥. ìµœì‹  í”„ë ˆì„ì„ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¼
frame_queue = queue.Queue(maxsize=1) 
# ë””ë²„ê·¸ ë° GUI í‘œì‹œìš© (YOLOê°€ ì²˜ë¦¬í•œ ìµœì¢… í”„ë ˆì„)
processed_frame_buffer = {"frame": None}

# ---------------------------------------------------------------------------
# 2. ë¡œë´‡ ê¸°ë³¸ ìì„¸/ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê°’ (v5.8 ì›ë³¸)
# ---------------------------------------------------------------------------
POSES = {
    "Home":  [59.8, -215.9, 354.6, -175.33, 8.65, 86.68],
    "Clear_Air_A": [264.0, -1.0, 379.0, -153, 11, -106],
    "Place_B": [333.0, 11.0, 170.0, -175, -0.08, -89.0],
}
DEFAULT_SPEED = 20
CAMERA_MATRIX = np.array([
    [539.13729067, 0.0, 329.02126026],
    [0.0, 542.34217387, 242.10995541],
    [0.0, 0.0, 1.0]
])
DIST_COEFFS = np.array([[0.20528603, -0.76664068, -0.00096614, 0.00111892, 0.97630004]])

# ---------------------------------------------------------------------------
# 3. í”½ì…€ ì¢Œí‘œ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜ (v5.8 ì›ë³¸)
# ---------------------------------------------------------------------------
def pixel_to_robot(cx, cy, distance_cm, frame_w, frame_h):
    pts = np.array([[[cx, cy]]], dtype=np.float32)
    undistorted_pts = cv2.undistortPoints(pts, CAMERA_MATRIX, DIST_COEFFS, P=None)
    norm_x, norm_y = undistorted_pts[0, 0]
    scale_z = distance_cm * 10.0
    x_cam = norm_x * scale_z
    y_cam = norm_y * scale_z
    
    TCP_BASE_OFFSET_X = 59.8
    TCP_BASE_OFFSET_Y = -215.9
    CAMERA_TO_TCP_OFFSET_X = 90.0 # (v5.8 ì›ë³¸ê°’)
    CAMERA_TO_TCP_OFFSET_Y = 0.0
    
    robot_x = TCP_BASE_OFFSET_X + CAMERA_TO_TCP_OFFSET_X + y_cam
    robot_y = TCP_BASE_OFFSET_Y + CAMERA_TO_TCP_OFFSET_Y + x_cam
    
    TCP_BASE_OFFSET_Z = 354.6
    robot_z_ignored = TCP_BASE_OFFSET_Z - scale_z
    
    return {"x": round(robot_x, 2), "y": round(robot_y, 2), "z_debug": round(robot_z_ignored, 2)}

# ---------------------------------------------------------------------------
# 4. [ì‹ ê·œ v5.9] ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ (ì´ˆê³ ì† ì˜ìƒ ìˆ˜ê¸‰)
# ---------------------------------------------------------------------------
def camera_read_thread(stop_event, cap, frame_queue):
    """ì˜¤ì§ cap.read()ë§Œ ë°˜ë³µí•˜ë©° Queueì— ìµœì‹  í”„ë ˆì„ì„ ê³µê¸‰"""
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì‹œì‘")
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue
        
        try:
            # íê°€ ê½‰ ì°¼ìœ¼ë©´(maxsize=1), ê¸°ì¡´ ê²ƒì„ ë²„ë¦¬ê³  ìƒˆ ê²ƒì„ ë„£ìŒ (non-blocking)
            frame_queue.put_nowait(frame) 
        except queue.Full:
            # íê°€ ê½‰ ì°¨ì„œ (YOLO ì²˜ë¦¬ê°€ ë°€ë ¤ì„œ) í”„ë ˆì„ì„ ë„£ì§€ ëª»í•  ë•Œ
            # ê·¸ëƒ¥ ì´ í”„ë ˆì„ì€ ë²„ë¦¬ê³  ë‹¤ìŒ í”„ë ˆì„ì„ ì½ìœ¼ëŸ¬ ê°
            pass
        
        time.sleep(0.01) # ì•½ 30~50fps ìœ ì§€ë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ sleep
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 5. [ìˆ˜ì • v5.9] 'YOLO ì²˜ë¦¬' ìŠ¤ë ˆë“œ (ëŠë¦° ë‘ë‡Œ)
# ---------------------------------------------------------------------------
def yolo_process_thread(stop_event, frame_queue, model):
    """Queueì—ì„œ í”„ë ˆì„ì„ êº¼ë‚´ì„œ YOLO ì˜ˆì¸¡ë§Œ ìˆ˜í–‰ (ëŠë¦¬ê²Œ ë™ì‘)"""
    global g_target_coordinate, g_coord_lock, processed_frame_buffer
    
    print("ğŸ§  YOLO 'ì²˜ë¦¬' ìŠ¤ë ˆë“œ ì‹œì‘")
    stable_frames = 0
    
    while not stop_event.is_set():
        # 1. ë¡œë´‡ì´ ì‘ì—… ì¤‘(e_robot_task_doneì´ False)ì´ë©´, íƒì§€ ì•ˆ í•¨
        if not e_robot_task_done.is_set():
            stable_frames = 0
            time.sleep(0.1)
            continue
            
        # 2. ë¡œë´‡ì´ ì‰¬ê³  ìˆìœ¼ë©´, Queueì—ì„œ ìµœì‹  í”„ë ˆì„ êº¼ë‚´ê¸°
        try:
            frame = frame_queue.get(timeout=0.1) # 0.1ì´ˆê°„ ê¸°ë‹¤ë¦¼
        except queue.Empty:
            continue # íê°€ ë¹„ì—ˆìœ¼ë©´ ë‹¤ì‹œ ëŒ€ê¸°

        # 3. YOLO ì˜ˆì¸¡ (ê°€ì¥ ëŠë¦° ë¶€ë¶„)
        results = model.predict(frame, imgsz=640, conf=0.6, verbose=False)
        boxes = results[0].boxes.xyxy.cpu().numpy()
        
        # 4. GUI í‘œì‹œìš© í”„ë ˆì„ ì €ì¥
        processed_frame_buffer["frame"] = results[0].plot()

        # 5. ë¬¼ì²´ ê°ì§€ ë° ì¢Œí‘œ ê³„ì‚°
        if len(boxes) > 0:
            stable_frames += 1
            if stable_frames >= 3: # 3í”„ë ˆì„ ì—°ì† ê°ì§€ ì‹œ "í™•ì •"
                x1, y1, x2, y2 = boxes[0]
                cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
                distance_cm = 30.0 # ì„ì‹œ ê³ ì •ê±°ë¦¬

                print(f"ğŸ¯ YOLO ê°ì²´ ì¤‘ì‹¬: ({cx}, {cy})")
                h, w, _ = frame.shape
                coord = pixel_to_robot(cx, cy, distance_cm, w, h)

                with g_coord_lock:
                    g_target_coordinate = coord
                
                e_robot_task_ready.set()  # ë¡œë´‡ ìŠ¤ë ˆë“œì—ê²Œ "ì¶œë°œ ì‹ í˜¸"
                e_robot_task_done.clear() # "íƒì§€ ì„ë¬´ ì™„ë£Œ, ë¡œë´‡ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°"
                stable_frames = 0
        else:
            stable_frames = 0
            
    print("ğŸ§  YOLO 'ì²˜ë¦¬' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 6. [ì‹ ê·œ v5.9] 'ë¡œë´‡ ì œì–´' ìŠ¤ë ˆë“œ (ëŠë¦° íŒ”ë‹¤ë¦¬)
# ---------------------------------------------------------------------------
def robot_control_thread(stop_event, mc, dry_run):
    """ë¡œë´‡ì˜ ëª¨ë“  ì›€ì§ì„(sleep í¬í•¨)ì„ ì „ë‹´"""
    global g_target_coordinate, g_coord_lock
    
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì‹œì‘")
    
    # 1. (ë”± í•œ ë²ˆ) í™ˆ ìœ„ì¹˜ë¡œ ì´ë™
    if not dry_run and mc is not None:
        print("ğŸ¤– ë¡œë´‡ì„ í™ˆ ìœ„ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
        mc.send_coords(POSES["Home"], DEFAULT_SPEED)
        time.sleep(3)
        print("ğŸ  í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ  [dry-run] í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
    e_robot_task_done.set() # YOLOê°€ íƒì§€ë¥¼ ì‹œì‘í•˜ë„ë¡ í—ˆìš©

    # 2. ë©”ì¸ ë£¨í”„ (ì‹ í˜¸ ëŒ€ê¸°)
    while not stop_event.is_set():
        # e_robot_task_ready ì‹ í˜¸ê°€ ì˜¬ ë•Œê¹Œì§€ ë¬´í•œì • ëŒ€ê¸° (Blocking)
        if not e_robot_task_ready.wait(timeout=0.5):
            continue # 0.5ì´ˆë§ˆë‹¤ stop_event ì²´í¬

        # ì‹ í˜¸ê°€ ì˜¤ë©´, ì¢Œí‘œë¥¼ ê°€ì ¸ì™€ì„œ ì „ì²´ ì‹œí€€ìŠ¤ ì‹¤í–‰
        current_coord = None
        with g_coord_lock:
            if g_target_coordinate is not None:
                current_coord = g_target_coordinate.copy()
                g_target_coordinate = None
        
        if current_coord:
            print(f"ğŸ¤– ì¸ì‹ ì„±ê³µ â†’ ë¡œë´‡ ì´ë™ ì‹œì‘: {current_coord}")
            pick_x = current_coord["x"]
            pick_y = current_coord["y"]

            # (v5.8 ì›ë³¸ ë¡œì§)
            GRIPPER_OFFSET_Z = 18.0
            FIXED_PICK_Z = 278.0
            APPROACH_HEIGHT = 40.0
            PICK_RX, PICK_RY, PICK_RZ = -175.33, 8.65, 86.68
            
            z_approach = FIXED_PICK_Z + APPROACH_HEIGHT
            z_grasp = FIXED_PICK_Z - GRIPPER_OFFSET_Z
            print(f"  â†³ ì ‘ê·¼Z={z_approach:.1f}, ì¡ê¸°Z={z_grasp:.1f}")

            if not dry_run and mc is not None:
                # --- v5.8 í”½ì—… ì‹œí€€ìŠ¤ (ì´ 20~25ì´ˆ ì†Œìš”) ---
                mc.set_gripper_state(0, 80)
                time.sleep(1)
                mc.send_coords([pick_x, pick_y, z_approach, PICK_RX, PICK_RY, PICK_RZ], 25, 1)
                time.sleep(5)
                mc.send_coords([pick_x, pick_y, z_grasp, PICK_RX, PICK_RY, PICK_RZ], 15, 1)
                time.sleep(1.5)
                mc.set_gripper_state(1, 80)
                time.sleep(1.5)
                
                # (v5.8 ì½”ë“œ ìˆ˜ì • - z_grasp + 80 ë¶€ë¶„)
                mc.send_coords([pick_x, pick_y, z_grasp + 80, PICK_RX, PICK_RY, PICK_RZ], 25, 1)
                time.sleep(2)
                # (z_approachë¡œ ë‹¤ì‹œ ì˜¬ë¦¬ê¸° - ì´ ì½”ë“œëŠ” ì¤‘ë³µ ê°™ì§€ë§Œ ì›ë³¸ ìœ ì§€)
                # mc.send_coords([pick_x, pick_y, z_approach, PICK_RX, PICK_RY, PICK_RZ], 25, 1)
                # time.sleep(2)
                
                mc.send_coords(POSES["Clear_Air_A"], DEFAULT_SPEED, 1)
                time.sleep(3)
                mc.send_coords(POSES["Place_B"], DEFAULT_SPEED, 1)
                time.sleep(3)
                mc.set_gripper_state(0, 80)
                time.sleep(1.5)
                mc.send_coords(POSES["Home"], DEFAULT_SPEED)
                time.sleep(3)
                print("âœ… 1íšŒ í”¼í‚¹ ì™„ë£Œ")
            else:
                print("  [dry-run] ë¡œë´‡ ì—†ì´ ë™ì‘ íë¦„ë§Œ ì‹¤í–‰")
                time.sleep(5) # ì‹œë®¬ë ˆì´ì…˜ ëŒ€ê¸°

            # ì‘ì—…ì´ ëë‚¬ìŒì„ ì•Œë¦¼
            e_robot_task_ready.clear() # "ì¶œë°œ ì‹ í˜¸" ë„ê¸°
            e_robot_task_done.set()  # YOLOì—ê²Œ "ë‹¤ì‹œ íƒì§€ ì‹œì‘" ì‹ í˜¸
            
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 7. ë©”ì¸ ë£¨í”„ (GUI ë‹´ë‹¹)
# ---------------------------------------------------------------------------
def main():
    global args

    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM0")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--speed", type=int, default=20)
    parser.add_argument("--camera", type=int, default=1)
    parser.add_argument("--dry-run", action="store_true")
    parser.add_argument("--model", type=str, default="best.pt")
    args = parser.parse_args()

    print(f"ğŸ§  YOLOv8 ëª¨ë¸('{args.model}') ë¡œë“œ ì¤‘...")
    try:
        model = YOLO(args.model, task="detect")
        print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
        
    stop_event = threading.Event()
    mc = None
    cap = None
    
    threads = [] # ì‹¤í–‰ëœ ìŠ¤ë ˆë“œë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸

    try:
        # 1) ë¡œë´‡ ì´ˆê¸°í™” (v5.8 ì›ë³¸)
        if not args.dry_run:
            try:
                mc = CobotClass(args.port, args.baud)
                time.sleep(0.5)
                mc.power_on()
                print("ğŸ”Œ ë¡œë´‡ Power ON ì™„ë£Œ")
                mc.set_gripper_state(0, 80)
                time.sleep(1)
            except Exception as e:
                print(f"âŒ ë¡œë´‡ ì—°ê²° ì‹¤íŒ¨: {e}")
                mc = None
                args.dry_run = True
        else:
            print("ğŸŸ¡ dry-run ëª¨ë“œë¡œ ì‹œì‘")

        # 2) ì¹´ë©”ë¼ ì´ˆê¸°í™” (v5.8 ì›ë³¸)
        print(f"ğŸ“· ë©”ì¸: ì¹´ë©”ë¼ {args.camera}ë²ˆ ì—´ê¸° ì‹œë„...")
        cap = cv2.VideoCapture(args.camera)
        if not cap.isOpened():
            print(f"âš ï¸ {args.camera}ë²ˆ ì¹´ë©”ë¼ ì‹¤íŒ¨ â†’ 0ë²ˆìœ¼ë¡œ ì¬ì‹œë„")
            cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise Exception("camera open failed")
        print("âœ… ë©”ì¸: ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ")

        # 3) [!!! v5.9 !!!] 3ê°œì˜ ìŠ¤ë ˆë“œ ì‹œì‘
        
        # Thread 1: ì¹´ë©”ë¼ ì½ê¸°
        t_cam = threading.Thread(
            target=camera_read_thread, 
            args=(stop_event, cap, frame_queue), 
            daemon=True
        )
        t_cam.start()
        threads.append(t_cam)

        # Thread 2: YOLO ì²˜ë¦¬
        t_yolo = threading.Thread(
            target=yolo_process_thread, 
            args=(stop_event, frame_queue, model), 
            daemon=True
        )
        t_yolo.start()
        threads.append(t_yolo)

        # Thread 3: ë¡œë´‡ ì œì–´
        t_robot = threading.Thread(
            target=robot_control_thread, 
            args=(stop_event, mc, args.dry_run), 
            daemon=True
        )
        t_robot.start()
        threads.append(t_robot)

        print("âœ… ë©”ì¸ ë£¨í”„ ì‹œì‘ (GUI í‘œì‹œ ë‹´ë‹¹, që¡œ ì¢…ë£Œ)")
        
        # 4) ë©”ì¸ ë£¨í”„ (GUIë§Œ ë‹´ë‹¹)
        while not stop_event.is_set():
            # YOLOê°€ ì²˜ë¦¬í•œ ìµœì¢… ê²°ê³¼ í”„ë ˆì„ì„ ê°€ì ¸ì˜´
            frame = processed_frame_buffer.get("frame")
            
            if frame is None:
                # YOLOê°€ ì•„ì§ ì²« í”„ë ˆì„ì„ ì²˜ë¦¬ ëª»í–ˆìœ¼ë©´ Queueì—ì„œ ì›ë³¸ì´ë¼ë„ ê°€ì ¸ì˜´
                try:
                    frame = frame_queue.get_nowait()
                except queue.Empty:
                    time.sleep(0.01)
                    continue

            cv2.imshow("Camera View", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()
                break
                
            time.sleep(0.01) # GUI ë£¨í”„ë„ ì•½ 30~50fpsë¡œ ì‹¤í–‰

    except Exception as e:
        print(f"ğŸš¨ ë©”ì¸ ë£¨í”„ì—ì„œ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        # 7) ì¢…ë£Œ ì²˜ë¦¬
        print("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€... ëª¨ë“  ìŠ¤ë ˆë“œ ì •ë¦¬ ì¤‘...")
        stop_event.set()
        
        for t in threads:
            t.join(timeout=1.0) # ìŠ¤ë ˆë“œê°€ 1ì´ˆ ì•ˆì— ëë‚˜ê¸¸ ê¸°ë‹¤ë¦¼
            
        if cap:
            cap.release()
        cv2.destroyAllWindows()
        if mc:
            mc.power_off()
        print("ğŸ”’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")


if __name__ == "__main__":
    main()
